<div align="center">
# RATransformers ğŸ­
[![PyPI - Latest Package Version](https://img.shields.io/pypi/v/ratransformers?logo=pypi&style=flat&color=orange)][#pypi-package]
[![GitHub - License](https://img.shields.io/github/license/JoaoLages/ratransformers?logo=github&style=flat&color=green)][#github-license]

![created by @JoaoLages](https://img.shields.io/badge/Created%20By-@JoaoLages-crimson?style=flat-square)
  
âš ğŸ‘·â€â™€ğŸ‘·â€â™‚  This package is WIP. Currently we only support the T5 model. Feel free to contribute with PRs!ï¸ğŸ‘·â€â™‚ğŸ‘·â€â™€âš 

**RATransformers**, short for Relation-Aware Transformers, is a package built on top of [transformers](https://github.com/huggingface/transformers)
that enables the training/fine-tuning of multiple models with some extra relation-aware weights. 
These extra weights enable the model to **encode explicit relations between different parts of the input data**.  
</div>
